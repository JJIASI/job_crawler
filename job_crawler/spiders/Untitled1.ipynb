{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.selector import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spider104(scrapy.Spider):\n",
    "    name='crawler104'\n",
    "    data = {\n",
    "        'ro': 0,\n",
    "        'kwop': 7,\n",
    "        'keyword': 'python',\n",
    "        'order': 1,\n",
    "        'asc': 0,\n",
    "        'page': 1,\n",
    "        'mode': 'l',  # 's' & 'l'\n",
    "        'jobsource': '2018indexpoc'\n",
    "    }\n",
    "    start_urls = ['https://www.104.com.tw/jobs/search/?' + urlencode(data)]\n",
    "    def parse(self, response):\n",
    "        selector = Selector(response)\n",
    "        jobname = selector.css('.js-job-link').xpath('@title').extract()\n",
    "        jobdate = selector.css('.job-mode__date::text').extract()[1:]\n",
    "        jobcompany = selector.css('.job-mode__company').css('a::text').extract()\n",
    "        jobexp = selector.css('.job-mode__exp::text').extract()[1:]\n",
    "        jobedu = selector.css('.job-mode__edu::text').extract()[1:]\n",
    "        jobarea = selector.css('.job-mode__area::text').extract()[1:]\n",
    "        for i in range(len(jobname)):\n",
    "            print(jobname[i], jobdate[i], jobcompany[i], jobexp[i], jobedu[i], jobarea[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.selector import Selector\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "from requests.exceptions import RequestException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_index(page, keyword):\n",
    "    data = {\n",
    "        'ro': 0,\n",
    "        'kwop': 7,\n",
    "        'keyword': keyword,\n",
    "        'order': 1,\n",
    "        'asc': 0,\n",
    "        'page': page,\n",
    "        'mode': 's',  # 's' & 'l'\n",
    "        'jobsource': '2018indexpoc'\n",
    "    }\n",
    "    url = 'https://www.104.com.tw/jobs/search/?' + urlencode(data)\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        return None\n",
    "    except RequestException:\n",
    "        print('Error')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_page_index(3,'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = Selector(response)\n",
    "# selector.xpath('//li[re:test(@class, \"job-mode__\\n$\")]').extract()\n",
    "jobsalary = selector.xpath('//div/span[1]/text()')[:-1].extract()\n",
    "jobname = selector.xpath('//article/@data-job-name').extract() #\n",
    "jobcompany = selector.xpath('//article/@data-cust-name').extract() #\n",
    "jobexp = selector.xpath('//div/ul[2]/li[2]/text()')[5:].extract() #\n",
    "jobedu = selector.xpath('//div/ul[2]/li[3]/text()')[2:].extract() \n",
    "jobarea = selector.xpath('//div/ul[2]/li[1]/text()')[5:].extract() #\n",
    "jobindcat = selector.xpath('//article/@data-indcat-desc').extract() #\n",
    "jobdate = selector.css('.b-tit__date')[3:] #\n",
    "jobapply = selector.xpath('.//div/a/text()')[2:-6].extract()\n",
    "len(jobsalary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdate = jobdate.xpath('.//text()').extract()[0].replace('\\n','').strip()\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "tmp_date = datetime.datetime.strptime('2019/12/02', \"%Y/%m/%d\")\n",
    "(now - tmp_date).days <0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def salary_mean(salary,pay_form):\n",
    "    if '~' in salary:\n",
    "        s = salary.split(pay_form)[1].split('元')[0].split('~')\n",
    "        func_t = lambda x:int(x.strip().replace(',',''))\n",
    "        return (func_t(s[0])+func_t(s[1]))*0.5\n",
    "    else:\n",
    "        s = salary.split(pay_form)[1].split('元')[0]\n",
    "        func_t = lambda x:int(x.strip().replace(',',''))\n",
    "        return func_t(s)\n",
    "\n",
    "salary_mean(h,'時薪')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(jobapply[4].split('~')[0].strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_get(page_n):\n",
    "    data = {\n",
    "        'ro': 0,\n",
    "        'kwop': 7,\n",
    "        'keyword': 'golang',\n",
    "        'order': 1,\n",
    "        'asc': 0,\n",
    "        'page': page_n,\n",
    "        'mode': 'l',  # 's' & 'l'\n",
    "        'jobsource': '2018indexpoc'\n",
    "    }\n",
    "    urls = 'https://www.104.com.tw/jobs/search/?' + urlencode(data)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'D:\\chromedrive\\chromedriver.exe')\n",
    "driver.get(url_get(1))\n",
    "html_text = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.http import HtmlResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = HtmlResponse(url_get(1), body=html_text, encoding=\"utf-8\")\n",
    "selector = Selector(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.css('select')[1].xpath('option/@value').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
